import json

from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain.tools import tool

@tool
def summarize_news_links(query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆì˜(ì˜ˆ: ì¢…ëª©ëª…)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³ ,
    ë³¸ë¬¸ì„ í¬ë¡¤ë§í•œ ë’¤ ìœ ì‚¬ë„ í•„í„°ë§ì„ ê±°ì³ GPT-4oë¡œ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤.
    """
    try:
        from news_tools.news_search import search_news
        raw = search_news.invoke(query)
        results = json.loads(raw)
        urls = [
            item.get("originallink") or item.get("link")
            for item in results
            if item.get("originallink") or item.get("link")
        ]
        print("[DEBUG] ë¶„ì„ ëŒ€ìƒ ë§í¬ ìˆ˜:", len(urls))
        print("[DEBUG] ë§í¬: ", urls)
        if not urls:
            return "âŒ ìœ íš¨í•œ ë‰´ìŠ¤ ë§í¬ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ë³¸ë¬¸ í¬ë¡¤ë§ ë° ë¡œë”© (SoupStrainer ì œê±° â†’ ì „ì²´ HTML íŒŒì‹±)
        loader = WebBaseLoader(web_paths=urls)
        docs = loader.load()
        if not docs:
            return "âŒ ë‰´ìŠ¤ ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨"

        # ë””ë²„ê¹… ì¶œë ¥
        print(f"[DEBUG] ìˆ˜ì§‘ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
        for i, doc in enumerate(docs):
            preview = doc.page_content[:200].replace("\n", " ").strip()
            print(f"[DEBUG] ë¬¸ì„œ {i+1}: ê¸¸ì´={len(doc.page_content)} / ë¯¸ë¦¬ë³´ê¸°: {preview}")

        # ë³¸ë¬¸ ì²­í¬ ë¶„í• 
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=30)
        splits = splitter.split_documents(docs)
        if not splits:
            return "âŒ ë‰´ìŠ¤ ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ì•„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ë²¡í„°ìŠ¤í† ì–´ ë° ìœ ì‚¬ë„ í•„í„°ë§
        vectorstore = FAISS.from_documents(splits, embedding=OpenAIEmbeddings())
        query_embedding = f"{query} ì£¼ì‹ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë‰´ìŠ¤ ìš”ì•½ ë° ì‚°ì—… ë¶„ì„"
        scored_results = vectorstore.similarity_search_with_score(query_embedding, k=50)
        keyword = query.strip()
        filtered_docs = [doc for doc, score in scored_results if score <= 0.3 and keyword in doc.page_content]

        if not filtered_docs:
            return "âŒ ìœ ì‚¬ë„ ë†’ì€ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # ë¶„ì„ ë¬¸ë§¥ êµ¬ì„±
        merged_context = "\n\n".join(doc.page_content for doc in filtered_docs)

        # ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì •ì˜
        prompt = PromptTemplate.from_template(
            f"""
            ë‹¤ìŒì€ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì¶”ì¶œí•œ ë¬¸ë§¥ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ '{query}' ê´€ë ¨ ë‚´ìš©ë§Œ ë¶„ì„í•˜ì„¸ìš”.
            ë‹¤ë¥¸ ê¸°ì—…, ì‚°ì—…ì€ ì–¸ê¸‰í•˜ë”ë¼ë„ ë¶„ì„ì—ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

            1. ğŸ“° í•µì‹¬ ìš”ì•½ (10ì¤„ ì´ë‚´)
            2. ğŸ“ˆ ê¸ì • ìš”ì¸ / ğŸ“‰ ë¶€ì • ìš”ì¸
            3. ğŸ”® ì‚°ì—… ë° ì£¼ê°€ ì˜í–¥ ìš”ì¸

            #Context:
            {{context}}

            #Answer:
            """
        )

        # LLM ë¶„ì„
        llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
        chain = (
            RunnablePassthrough.assign(context=lambda _: merged_context)
            | prompt
            | llm
            | StrOutputParser()
        )

        return chain.invoke({})

    except Exception as e:
        return f"âŒ ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# ë‹¨ë… ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print(summarize_news_links.invoke("ì‚¼ì„±ì „ì"))