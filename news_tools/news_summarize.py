import os
import json
from dotenv import load_dotenv
from langchain.tools import tool
from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from requests.exceptions import SSLError, RequestException

load_dotenv()

#ì•ˆì „í•˜ê²Œ ë¬¸ì„œ ë¡œë”©í•˜ëŠ” í•¨ìˆ˜ (SSL ì˜ˆì™¸ ì œê±°)
def safe_load_documents(urls: list[str]) -> list:
    valid_docs = []
    for url in urls:
        try:
            loader = WebBaseLoader(url)
            docs = loader.load()
            if docs:
                valid_docs.extend(docs)
        except SSLError as e:
            print(f"[SSL ì œì™¸] {url} â†’ {e}")
        except RequestException as e:
            print(f"[ìš”ì²­ ì‹¤íŒ¨ ì œì™¸] {url} â†’ {e}")
        except Exception as e:
            print(f"[ê¸°íƒ€ ì˜ˆì™¸ ì œì™¸] {url} â†’ {e}")
    return valid_docs

@tool
def summarize_news_links(query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆì˜(ì˜ˆ: ì¢…ëª©ëª…)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³ ,
    ë³¸ë¬¸ì„ í¬ë¡¤ë§í•œ ë’¤ ìœ ì‚¬ë„ í•„í„°ë§ì„ ê±°ì³ GPT-4oë¡œ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤.
    """
    try:
        from news_tools.news_search import search_news
        raw = search_news.invoke(query)
        results = json.loads(raw)
        urls = [
            item.get("originallink") or item.get("link")
            for item in results
            if item.get("originallink") or item.get("link")
        ]
        print("[DEBUG] ë¶„ì„ ëŒ€ìƒ ë§í¬ ìˆ˜:", len(urls))
        if not urls:
            return "âŒ ìœ íš¨í•œ ë‰´ìŠ¤ ë§í¬ê°€ ì—†ìŠµë‹ˆë‹¤."

        # âœ… ì•ˆì „í•˜ê²Œ ë¬¸ì„œ ë¡œë”©
        docs = safe_load_documents(urls)
        if not docs:
            return "âŒ ìœ íš¨í•œ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        print(f"[DEBUG] ìˆ˜ì§‘ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

        # ë³¸ë¬¸ ì²­í¬ ë¶„í• 
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=30)
        splits = splitter.split_documents(docs)
        if not splits:
            return "âŒ ë‰´ìŠ¤ ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ì•„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        print(f"[DEBUG] ì´ ì²­í¬ ìˆ˜: {len(splits)}")

        # ë²¡í„°ìŠ¤í† ì–´ ë° ìœ ì‚¬ë„ í•„í„°ë§
        vectorstore = FAISS.from_documents(splits, embedding=OpenAIEmbeddings())
        query_embedding = f"{query} ì£¼ì‹ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë‰´ìŠ¤ ìš”ì•½ ë° ë¶„ì„"
        scored_results = vectorstore.similarity_search_with_score(query_embedding, k=50)
        keyword = query.strip()
        filtered_docs = [doc for doc, score in scored_results if score <= 0.35 and keyword in doc.page_content]
        if not filtered_docs:
            return "âŒ ìœ ì‚¬ë„ ë†’ì€ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # ë¶„ì„ ë¬¸ë§¥ êµ¬ì„±
        merged_context = "\n\n".join(doc.page_content for doc in filtered_docs)

        # í”„ë¡¬í”„íŠ¸ ì •ì˜
        # í”„ë¡¬í”„íŠ¸ ì •ì˜
        prompt = PromptTemplate.from_template(
            f"""
        ë‹¹ì‹ ì€ ê¸ˆìœµ ë¦¬ì„œì¹˜ ì„¼í„°ì˜ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.  
        ë‹¤ìŒì€ íŠ¹ì • ê¸°ì—… ë˜ëŠ” ì‚°ì—…ì— ëŒ€í•œ ë‰´ìŠ¤ ë¬¸ë§¥(Context)ì…ë‹ˆë‹¤.

        ğŸ¯ ë¶„ì„ ëŒ€ìƒ í‚¤ì›Œë“œ: **'{query}'**

        ğŸ›‘ ë¶„ì„ ì§€ì¹¨:
        - ë¬¸ë§¥ì— ë“±ì¥í•˜ëŠ” ë‹¤ë¥¸ ê¸°ì—…ì´ë‚˜ ì‚°ì—…ì´ ìˆë‹¤ í•˜ë”ë¼ë„, **'{query}'ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ë§Œ ë¶„ì„ ëŒ€ìƒì— í¬í•¨**í•˜ì„¸ìš”.
        - **ì¶”ì¸¡ì€ ê¸ˆì§€**í•˜ë©°, **ë¬¸ë§¥ ë‚´ ëª…ì‹œëœ ì‚¬ì‹¤**ì— ê¸°ë°˜í•´ ë¶„ì„í•˜ì„¸ìš”.
        - **ë¬¸ë‹¨ ìš”ì•½ì€ ê¸ˆì§€**í•˜ë©°, **ê° í•­ëª©ì€ ëª…í™•í•œ í¬ì¸íŠ¸ ê¸°ë°˜ bullet í˜•ì‹ìœ¼ë¡œ ì‘ì„±**í•˜ì„¸ìš”.
        - ì–´ì¡°ëŠ” **ê°ê´€ì ì´ê³  ë¶„ì„ì ì´ë©°**, **íˆ¬ìì ë¦¬í¬íŠ¸ í˜•ì‹ì— ì¤€í•˜ë„ë¡ ì •ì œëœ í‘œí˜„**ì„ ì‚¬ìš©í•˜ì„¸ìš”.

        ë¶„ì„ì€ ì•„ë˜ í•­ëª© ìˆœì„œì— ë”°ë¼ ì‘ì„±í•˜ì„¸ìš”:

        ---

        ### 1. ğŸ§¾ í•µì‹¬ ìš”ì•½ (ìµœëŒ€ 10ì¤„, bullet point)
        - ë‚ ì§œ ê¸°ë°˜ ë˜ëŠ” íë¦„ ê¸°ë°˜ìœ¼ë¡œ ì£¼ìš” ì‚¬ì‹¤ì„ ì •ë¦¬í•˜ì„¸ìš”.
        - ì ˆëŒ€ë¡œ ë¬¸ë‹¨ ìš”ì•½ í˜•íƒœë¡œ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.

        ### 2. âœ… ìš°í˜¸ì  ìš”ì¸ (ê¸ì •ì  ìš”ì¸, ìµœì†Œ 5ê°€ì§€)
        - ê¸°ì—… ë˜ëŠ” ì‚°ì—…ì— ê¸ì •ì ìœ¼ë¡œ ì‘ìš©í•  ìˆ˜ ìˆëŠ” íŒ©íŠ¸ ë˜ëŠ” ì‹œì‚¬ì ì„ bulletë¡œ ì‘ì„±í•˜ì„¸ìš”.

        ### 3. âš ï¸ ìœ„í—˜ ìš”ì¸ (ë¶€ì •ì  ìš”ì¸, ìµœì†Œ 5ê°€ì§€)
        - ì ì¬ì  ë¦¬ìŠ¤í¬ë‚˜ ì‹œì¥ ë°˜ì‘ ê°€ëŠ¥ì„±ì„ bulletë¡œ ì‘ì„±í•˜ì„¸ìš”.

        ### 4. ğŸ“Š ì‚°ì—… ë° ì£¼ê°€ ì˜í–¥ ìš”ì¸ (ìµœì†Œ 5ê°€ì§€)
        - ë‰´ìŠ¤ê°€ ì‚°ì—…/ì£¼ê°€ì— ë¯¸ì¹  ìˆ˜ ìˆëŠ” ë‹¨ê¸°ì  ë˜ëŠ” ì¤‘ì¥ê¸°ì  ì˜í–¥ ìš”ì¸ì„ ë¶„ì„í•˜ì„¸ìš”.
        - **ë‹¨ê¸° vs ì¤‘ì¥ê¸° êµ¬ë¶„**ì´ ê°€ëŠ¥í•˜ë©´ ëª…ì‹œí•˜ì„¸ìš”.

        ---

        #Context:
        {{context}}
        """
        )

        # ë¶„ì„ ì²´ì¸
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
        chain = (
            RunnablePassthrough.assign(context=lambda _: merged_context)
            | prompt
            | llm
            | StrOutputParser()
        )

        return chain.invoke({})

    except Exception as e:
        return f"âŒ ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {type(e).__name__}: {e}"

# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰
if __name__ == "__main__":
    print(summarize_news_links.invoke("ì‚¼ì„±ì „ì"))