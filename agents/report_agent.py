from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
import json

#LLM ì •ì˜
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

#í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
report_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "ë„ˆëŠ” ì£¼ì‹ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ì „ë¬¸ ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ì•¼. "
     "ì‚¬ìš©ìëŠ” ê°œì¸ íˆ¬ììì´ë©°, ê¸°ìˆ ì  ë¶„ì„, ë‰´ìŠ¤, ì¬ë¬´ì œí‘œ, ì£¼ê°€ íë¦„ ë“± ë‹¤ì–‘í•œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì›í•˜ê³  ìˆì–´.\n\n"
     "ì•„ë˜ ë‚´ìš©ì„ í¬í•¨í•´ì„œ ì‹ ë¢°ë„ ë†’ì€ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•´:\n"
     "1. ğŸ“Œ ì‚¬ìš©ì ìš”ì²­ ìš”ì•½\n"
     "2. ğŸ§© ê° ë¶„ì„ ë„êµ¬ì˜ í•µì‹¬ ê²°ê³¼ ìš”ì•½ (ë„êµ¬ëª… ëª…ì‹œ)\n"
     "3. ğŸ” ì¢…í•© í•´ì„ ë° íˆ¬ì ì°¸ê³  ì‚¬í•­ (ê¸°íšŒ ìš”ì¸, ìœ„í—˜ ìš”ì¸ ë“±)\n\n"
     "â€» ì‘ì„± ì›ì¹™:\n"
     "- ê° ë„êµ¬ì˜ ê²°ê³¼ë¥¼ ì •í™•í•˜ê³  í•µì‹¬ì ìœ¼ë¡œ ìš”ì•½í•´ì•¼ í•´.\n"
     "- ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹ˆë¼ ê²°ê³¼ë“¤ ì‚¬ì´ì˜ ì˜ë¯¸ë¥¼ ì—°ê²°í•´ ì¢…í•©ì ì¸ íŒë‹¨ì„ ì œì‹œí•´ì•¼ í•´.\n"
     "- ì¶”ì¸¡ì„± í•´ì„ì€ ì§€ì–‘í•˜ê³ , ë°ì´í„°ì— ê¸°ë°˜í•œ ë¶„ì„ì„ í•´ì•¼ í•´.\n"
     "- ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, ê°œì¸ íˆ¬ììê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì ì ˆí•œ ìš©ì–´ ìˆ˜ì¤€ì„ ìœ ì§€í•´ì•¼ í•´."),
    ("human", "{input}")
])

#ì—ì´ì „íŠ¸ ìƒì„±
report_agent = create_tool_calling_agent(
    llm=llm,
    tools=[],
    prompt=report_prompt
)

report_executor = AgentExecutor(
    agent=report_agent,
    tools=[],
    verbose=True
)

# âœ… LangGraphìš© ë…¸ë“œ í•¨ìˆ˜
def generate_report_node(state: dict) -> dict:
    query = state["input"]
    result = state["result"]

    full_prompt = (
        f"ì‚¬ìš©ì ìš”ì²­: {query}\n"
        f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:\n{json.dumps(result, ensure_ascii=False)}"
    )

    response = report_executor.invoke({"input": full_prompt})
    return {"report": response.get("output", response)}
